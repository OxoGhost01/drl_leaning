[2025-09-23 22:29:47,305][18541] Saving configuration to /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/config.json...
[2025-09-23 22:29:47,313][18541] Rollout worker 0 uses device cpu
[2025-09-23 22:29:47,313][18541] Rollout worker 1 uses device cpu
[2025-09-23 22:29:47,313][18541] Rollout worker 2 uses device cpu
[2025-09-23 22:29:47,313][18541] Rollout worker 3 uses device cpu
[2025-09-23 22:29:47,314][18541] Rollout worker 4 uses device cpu
[2025-09-23 22:29:47,314][18541] Rollout worker 5 uses device cpu
[2025-09-23 22:29:47,314][18541] Rollout worker 6 uses device cpu
[2025-09-23 22:29:47,314][18541] Rollout worker 7 uses device cpu
[2025-09-23 22:29:47,398][18541] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-09-23 22:29:47,398][18541] InferenceWorker_p0-w0: min num requests: 2
[2025-09-23 22:29:47,427][18541] Starting all processes...
[2025-09-23 22:29:47,427][18541] Starting process learner_proc0
[2025-09-23 22:29:48,840][18541] Starting all processes...
[2025-09-23 22:29:48,844][18636] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-09-23 22:29:48,844][18636] Set environment var CUDA_VISIBLE_DEVICES to '0' (GPU indices [0]) for learning process 0
[2025-09-23 22:29:48,845][18541] Starting process inference_proc0-0
[2025-09-23 22:29:48,845][18541] Starting process rollout_proc0
[2025-09-23 22:29:48,845][18541] Starting process rollout_proc1
[2025-09-23 22:29:48,845][18541] Starting process rollout_proc2
[2025-09-23 22:29:48,848][18541] Starting process rollout_proc3
[2025-09-23 22:29:48,848][18541] Starting process rollout_proc4
[2025-09-23 22:29:48,849][18541] Starting process rollout_proc5
[2025-09-23 22:29:48,853][18636] Num visible devices: 1
[2025-09-23 22:29:48,855][18636] Starting seed is not provided
[2025-09-23 22:29:48,855][18636] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-09-23 22:29:48,855][18636] Initializing actor-critic model on device cuda:0
[2025-09-23 22:29:48,856][18636] RunningMeanStd input shape: (3, 72, 128)
[2025-09-23 22:29:48,849][18541] Starting process rollout_proc6
[2025-09-23 22:29:48,857][18636] RunningMeanStd input shape: (1,)
[2025-09-23 22:29:48,851][18541] Starting process rollout_proc7
[2025-09-23 22:29:48,871][18636] ConvEncoder: input_channels=3
[2025-09-23 22:29:49,056][18636] Conv encoder output size: 512
[2025-09-23 22:29:49,057][18636] Policy head output size: 512
[2025-09-23 22:29:49,078][18636] Created Actor Critic model with architecture:
[2025-09-23 22:29:49,078][18636] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): VizdoomEncoder(
    (basic_encoder): ConvEncoder(
      (enc): RecursiveScriptModule(
        original_name=ConvEncoderImpl
        (conv_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Conv2d)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Conv2d)
          (3): RecursiveScriptModule(original_name=ELU)
          (4): RecursiveScriptModule(original_name=Conv2d)
          (5): RecursiveScriptModule(original_name=ELU)
        )
        (mlp_layers): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(512, 512)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=512, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=512, out_features=5, bias=True)
  )
)
[2025-09-23 22:29:49,288][18636] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-09-23 22:29:50,711][18636] No checkpoints found
[2025-09-23 22:29:50,711][18636] Did not load from checkpoint, starting from scratch!
[2025-09-23 22:29:50,711][18636] Initialized policy 0 weights for model version 0
[2025-09-23 22:29:50,714][18636] LearnerWorker_p0 finished initialization!
[2025-09-23 22:29:50,714][18636] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-09-23 22:29:50,776][18681] Worker 7 uses CPU cores [14, 15]
[2025-09-23 22:29:50,803][18673] Worker 0 uses CPU cores [0, 1]
[2025-09-23 22:29:50,827][18674] Worker 1 uses CPU cores [2, 3]
[2025-09-23 22:29:50,887][18677] Worker 2 uses CPU cores [4, 5]
[2025-09-23 22:29:50,921][18676] Worker 3 uses CPU cores [6, 7]
[2025-09-23 22:29:50,936][18678] Worker 4 uses CPU cores [8, 9]
[2025-09-23 22:29:51,195][18680] Worker 5 uses CPU cores [10, 11]
[2025-09-23 22:29:51,282][18672] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-09-23 22:29:51,282][18672] Set environment var CUDA_VISIBLE_DEVICES to '0' (GPU indices [0]) for inference process 0
[2025-09-23 22:29:51,291][18672] Num visible devices: 1
[2025-09-23 22:29:51,339][18672] RunningMeanStd input shape: (3, 72, 128)
[2025-09-23 22:29:51,340][18672] RunningMeanStd input shape: (1,)
[2025-09-23 22:29:51,347][18672] ConvEncoder: input_channels=3
[2025-09-23 22:29:51,405][18541] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-23 22:29:51,407][18672] Conv encoder output size: 512
[2025-09-23 22:29:51,407][18672] Policy head output size: 512
[2025-09-23 22:29:51,408][18679] Worker 6 uses CPU cores [12, 13]
[2025-09-23 22:29:51,430][18541] Inference worker 0-0 is ready!
[2025-09-23 22:29:51,430][18541] All inference workers are ready! Signal rollout workers to start!
[2025-09-23 22:29:51,454][18676] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:29:51,454][18680] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:29:51,454][18674] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:29:51,454][18673] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:29:51,454][18678] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:29:51,454][18677] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:29:51,472][18681] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:29:51,472][18679] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:29:51,655][18673] Decorrelating experience for 0 frames...
[2025-09-23 22:29:51,655][18674] Decorrelating experience for 0 frames...
[2025-09-23 22:29:51,655][18678] Decorrelating experience for 0 frames...
[2025-09-23 22:29:51,655][18680] Decorrelating experience for 0 frames...
[2025-09-23 22:29:51,656][18677] Decorrelating experience for 0 frames...
[2025-09-23 22:29:51,795][18681] Decorrelating experience for 0 frames...
[2025-09-23 22:29:51,795][18679] Decorrelating experience for 0 frames...
[2025-09-23 22:29:51,812][18673] Decorrelating experience for 32 frames...
[2025-09-23 22:29:51,812][18678] Decorrelating experience for 32 frames...
[2025-09-23 22:29:51,812][18680] Decorrelating experience for 32 frames...
[2025-09-23 22:29:51,846][18676] Decorrelating experience for 0 frames...
[2025-09-23 22:29:51,967][18677] Decorrelating experience for 32 frames...
[2025-09-23 22:29:52,014][18673] Decorrelating experience for 64 frames...
[2025-09-23 22:29:52,015][18674] Decorrelating experience for 32 frames...
[2025-09-23 22:29:52,077][18681] Decorrelating experience for 32 frames...
[2025-09-23 22:29:52,125][18679] Decorrelating experience for 32 frames...
[2025-09-23 22:29:52,162][18677] Decorrelating experience for 64 frames...
[2025-09-23 22:29:52,166][18680] Decorrelating experience for 64 frames...
[2025-09-23 22:29:52,190][18673] Decorrelating experience for 96 frames...
[2025-09-23 22:29:52,289][18678] Decorrelating experience for 64 frames...
[2025-09-23 22:29:52,312][18676] Decorrelating experience for 32 frames...
[2025-09-23 22:29:52,340][18677] Decorrelating experience for 96 frames...
[2025-09-23 22:29:52,340][18680] Decorrelating experience for 96 frames...
[2025-09-23 22:29:52,434][18681] Decorrelating experience for 64 frames...
[2025-09-23 22:29:52,470][18678] Decorrelating experience for 96 frames...
[2025-09-23 22:29:52,518][18674] Decorrelating experience for 64 frames...
[2025-09-23 22:29:52,632][18679] Decorrelating experience for 64 frames...
[2025-09-23 22:29:52,690][18674] Decorrelating experience for 96 frames...
[2025-09-23 22:29:52,757][18681] Decorrelating experience for 96 frames...
[2025-09-23 22:29:52,867][18676] Decorrelating experience for 64 frames...
[2025-09-23 22:29:52,955][18679] Decorrelating experience for 96 frames...
[2025-09-23 22:29:53,043][18676] Decorrelating experience for 96 frames...
[2025-09-23 22:29:53,124][18636] Signal inference workers to stop experience collection...
[2025-09-23 22:29:53,127][18672] InferenceWorker_p0-w0: stopping experience collection
[2025-09-23 22:29:54,024][18636] Signal inference workers to resume experience collection...
[2025-09-23 22:29:54,024][18672] InferenceWorker_p0-w0: resuming experience collection
[2025-09-23 22:29:54,365][18541] Fps is (10 sec: 4151.4, 60 sec: 4151.4, 300 sec: 4151.4). Total num frames: 12288. Throughput: 0: 0.0. Samples: 0. Policy #0 lag: (min: 0.0, avg: 0.0, max: 0.0)
[2025-09-23 22:29:54,366][18541] Avg episode reward: [(0, '3.028')]
[2025-09-23 22:29:55,512][18672] Updated weights for policy 0, policy_version 10 (0.0056)
[2025-09-23 22:29:57,140][18672] Updated weights for policy 0, policy_version 20 (0.0011)
[2025-09-23 22:29:58,856][18672] Updated weights for policy 0, policy_version 30 (0.0009)
[2025-09-23 22:29:59,365][18541] Fps is (10 sec: 16981.1, 60 sec: 16981.1, 300 sec: 16981.1). Total num frames: 135168. Throughput: 0: 2894.0. Samples: 23036. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:29:59,376][18541] Avg episode reward: [(0, '4.429')]
[2025-09-23 22:29:59,377][18636] Saving new best policy, reward=4.429!
[2025-09-23 22:30:00,425][18672] Updated weights for policy 0, policy_version 40 (0.0011)
[2025-09-23 22:30:02,062][18672] Updated weights for policy 0, policy_version 50 (0.0009)
[2025-09-23 22:30:03,782][18672] Updated weights for policy 0, policy_version 60 (0.0010)
[2025-09-23 22:30:04,365][18541] Fps is (10 sec: 24985.6, 60 sec: 20227.2, 300 sec: 20227.2). Total num frames: 262144. Throughput: 0: 4598.9. Samples: 59602. Policy #0 lag: (min: 0.0, avg: 0.8, max: 2.0)
[2025-09-23 22:30:04,366][18541] Avg episode reward: [(0, '4.565')]
[2025-09-23 22:30:04,370][18636] Saving new best policy, reward=4.565!
[2025-09-23 22:30:05,301][18672] Updated weights for policy 0, policy_version 70 (0.0010)
[2025-09-23 22:30:06,966][18672] Updated weights for policy 0, policy_version 80 (0.0009)
[2025-09-23 22:30:07,371][18541] Heartbeat connected on Batcher_0
[2025-09-23 22:30:07,384][18541] Heartbeat connected on LearnerWorker_p0
[2025-09-23 22:30:07,401][18541] Heartbeat connected on InferenceWorker_p0-w0
[2025-09-23 22:30:07,407][18541] Heartbeat connected on RolloutWorker_w0
[2025-09-23 22:30:07,411][18541] Heartbeat connected on RolloutWorker_w1
[2025-09-23 22:30:07,415][18541] Heartbeat connected on RolloutWorker_w2
[2025-09-23 22:30:07,416][18541] Heartbeat connected on RolloutWorker_w3
[2025-09-23 22:30:07,419][18541] Heartbeat connected on RolloutWorker_w4
[2025-09-23 22:30:07,423][18541] Heartbeat connected on RolloutWorker_w5
[2025-09-23 22:30:07,427][18541] Heartbeat connected on RolloutWorker_w7
[2025-09-23 22:30:07,427][18541] Heartbeat connected on RolloutWorker_w6
[2025-09-23 22:30:08,642][18672] Updated weights for policy 0, policy_version 90 (0.0009)
[2025-09-23 22:30:09,365][18541] Fps is (10 sec: 24985.4, 60 sec: 21437.9, 300 sec: 21437.9). Total num frames: 385024. Throughput: 0: 4399.8. Samples: 79020. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:30:09,366][18541] Avg episode reward: [(0, '4.614')]
[2025-09-23 22:30:09,379][18636] Saving new best policy, reward=4.614!
[2025-09-23 22:30:10,189][18672] Updated weights for policy 0, policy_version 100 (0.0010)
[2025-09-23 22:30:11,808][18672] Updated weights for policy 0, policy_version 110 (0.0011)
[2025-09-23 22:30:13,470][18672] Updated weights for policy 0, policy_version 120 (0.0010)
[2025-09-23 22:30:14,365][18541] Fps is (10 sec: 24985.5, 60 sec: 22299.6, 300 sec: 22299.6). Total num frames: 512000. Throughput: 0: 5105.6. Samples: 117224. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)
[2025-09-23 22:30:14,366][18541] Avg episode reward: [(0, '4.936')]
[2025-09-23 22:30:14,368][18636] Saving new best policy, reward=4.936!
[2025-09-23 22:30:15,018][18672] Updated weights for policy 0, policy_version 130 (0.0008)
[2025-09-23 22:30:16,537][18672] Updated weights for policy 0, policy_version 140 (0.0009)
[2025-09-23 22:30:18,218][18672] Updated weights for policy 0, policy_version 150 (0.0010)
[2025-09-23 22:30:19,366][18541] Fps is (10 sec: 25804.4, 60 sec: 22999.6, 300 sec: 22999.6). Total num frames: 643072. Throughput: 0: 5572.3. Samples: 155802. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:30:19,366][18541] Avg episode reward: [(0, '4.993')]
[2025-09-23 22:30:19,366][18636] Saving new best policy, reward=4.993!
[2025-09-23 22:30:19,781][18672] Updated weights for policy 0, policy_version 160 (0.0009)
[2025-09-23 22:30:21,431][18672] Updated weights for policy 0, policy_version 170 (0.0009)
[2025-09-23 22:30:23,120][18672] Updated weights for policy 0, policy_version 180 (0.0008)
[2025-09-23 22:30:24,366][18541] Fps is (10 sec: 24985.0, 60 sec: 23114.4, 300 sec: 23114.4). Total num frames: 761856. Throughput: 0: 5304.4. Samples: 174834. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:30:24,366][18541] Avg episode reward: [(0, '5.390')]
[2025-09-23 22:30:24,371][18636] Saving new best policy, reward=5.390!
[2025-09-23 22:30:24,902][18672] Updated weights for policy 0, policy_version 190 (0.0009)
[2025-09-23 22:30:26,596][18672] Updated weights for policy 0, policy_version 200 (0.0009)
[2025-09-23 22:30:28,132][18672] Updated weights for policy 0, policy_version 210 (0.0009)
[2025-09-23 22:30:29,365][18541] Fps is (10 sec: 24576.4, 60 sec: 23415.0, 300 sec: 23415.0). Total num frames: 888832. Throughput: 0: 5559.7. Samples: 211046. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)
[2025-09-23 22:30:29,366][18541] Avg episode reward: [(0, '5.259')]
[2025-09-23 22:30:29,860][18672] Updated weights for policy 0, policy_version 220 (0.0009)
[2025-09-23 22:30:31,547][18672] Updated weights for policy 0, policy_version 230 (0.0010)
[2025-09-23 22:30:33,222][18672] Updated weights for policy 0, policy_version 240 (0.0009)
[2025-09-23 22:30:34,365][18541] Fps is (10 sec: 24576.4, 60 sec: 23454.7, 300 sec: 23454.7). Total num frames: 1007616. Throughput: 0: 5766.8. Samples: 247742. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:30:34,366][18541] Avg episode reward: [(0, '5.702')]
[2025-09-23 22:30:34,370][18636] Saving new best policy, reward=5.702!
[2025-09-23 22:30:34,904][18672] Updated weights for policy 0, policy_version 250 (0.0011)
[2025-09-23 22:30:36,569][18672] Updated weights for policy 0, policy_version 260 (0.0010)
[2025-09-23 22:30:38,215][18672] Updated weights for policy 0, policy_version 270 (0.0009)
[2025-09-23 22:30:39,365][18541] Fps is (10 sec: 24576.0, 60 sec: 23657.0, 300 sec: 23657.0). Total num frames: 1134592. Throughput: 0: 5910.1. Samples: 265956. Policy #0 lag: (min: 0.0, avg: 0.7, max: 1.0)
[2025-09-23 22:30:39,366][18541] Avg episode reward: [(0, '6.205')]
[2025-09-23 22:30:39,366][18636] Saving new best policy, reward=6.205!
[2025-09-23 22:30:39,748][18672] Updated weights for policy 0, policy_version 280 (0.0009)
[2025-09-23 22:30:41,324][18672] Updated weights for policy 0, policy_version 290 (0.0008)
[2025-09-23 22:30:43,009][18672] Updated weights for policy 0, policy_version 300 (0.0009)
[2025-09-23 22:30:44,365][18541] Fps is (10 sec: 24985.8, 60 sec: 23743.8, 300 sec: 23743.8). Total num frames: 1257472. Throughput: 0: 6252.9. Samples: 304416. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)
[2025-09-23 22:30:44,366][18541] Avg episode reward: [(0, '7.138')]
[2025-09-23 22:30:44,396][18636] Saving new best policy, reward=7.138!
[2025-09-23 22:30:44,697][18672] Updated weights for policy 0, policy_version 310 (0.0009)
[2025-09-23 22:30:46,349][18672] Updated weights for policy 0, policy_version 320 (0.0009)
[2025-09-23 22:30:48,053][18672] Updated weights for policy 0, policy_version 330 (0.0009)
[2025-09-23 22:30:49,366][18541] Fps is (10 sec: 24985.0, 60 sec: 23886.2, 300 sec: 23886.2). Total num frames: 1384448. Throughput: 0: 6257.1. Samples: 341174. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:30:49,366][18541] Avg episode reward: [(0, '7.712')]
[2025-09-23 22:30:49,367][18636] Saving new best policy, reward=7.712!
[2025-09-23 22:30:49,720][18672] Updated weights for policy 0, policy_version 340 (0.0009)
[2025-09-23 22:30:51,311][18672] Updated weights for policy 0, policy_version 350 (0.0009)
[2025-09-23 22:30:53,130][18672] Updated weights for policy 0, policy_version 360 (0.0010)
[2025-09-23 22:30:54,366][18541] Fps is (10 sec: 24575.8, 60 sec: 24849.0, 300 sec: 23875.9). Total num frames: 1503232. Throughput: 0: 6238.8. Samples: 359766. Policy #0 lag: (min: 0.0, avg: 0.8, max: 2.0)
[2025-09-23 22:30:54,366][18541] Avg episode reward: [(0, '10.599')]
[2025-09-23 22:30:54,370][18636] Saving new best policy, reward=10.599!
[2025-09-23 22:30:54,756][18672] Updated weights for policy 0, policy_version 370 (0.0010)
[2025-09-23 22:30:56,383][18672] Updated weights for policy 0, policy_version 380 (0.0008)
[2025-09-23 22:30:58,141][18672] Updated weights for policy 0, policy_version 390 (0.0010)
[2025-09-23 22:30:59,365][18541] Fps is (10 sec: 24167.1, 60 sec: 24849.1, 300 sec: 23927.5). Total num frames: 1626112. Throughput: 0: 6210.5. Samples: 396696. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:30:59,366][18541] Avg episode reward: [(0, '12.045')]
[2025-09-23 22:30:59,366][18636] Saving new best policy, reward=12.045!
[2025-09-23 22:30:59,807][18672] Updated weights for policy 0, policy_version 400 (0.0010)
[2025-09-23 22:31:01,420][18672] Updated weights for policy 0, policy_version 410 (0.0009)
[2025-09-23 22:31:03,004][18672] Updated weights for policy 0, policy_version 420 (0.0009)
[2025-09-23 22:31:04,365][18541] Fps is (10 sec: 24985.9, 60 sec: 24849.0, 300 sec: 24028.1). Total num frames: 1753088. Throughput: 0: 6180.0. Samples: 433900. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)
[2025-09-23 22:31:04,366][18541] Avg episode reward: [(0, '12.957')]
[2025-09-23 22:31:04,370][18636] Saving new best policy, reward=12.957!
[2025-09-23 22:31:04,609][18672] Updated weights for policy 0, policy_version 430 (0.0010)
[2025-09-23 22:31:06,351][18672] Updated weights for policy 0, policy_version 440 (0.0010)
[2025-09-23 22:31:08,042][18672] Updated weights for policy 0, policy_version 450 (0.0010)
[2025-09-23 22:31:09,366][18541] Fps is (10 sec: 24985.2, 60 sec: 24849.0, 300 sec: 24063.2). Total num frames: 1875968. Throughput: 0: 6152.7. Samples: 451704. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:31:09,366][18541] Avg episode reward: [(0, '17.348')]
[2025-09-23 22:31:09,367][18636] Saving new best policy, reward=17.348!
[2025-09-23 22:31:09,711][18672] Updated weights for policy 0, policy_version 460 (0.0009)
[2025-09-23 22:31:11,347][18672] Updated weights for policy 0, policy_version 470 (0.0010)
[2025-09-23 22:31:12,861][18672] Updated weights for policy 0, policy_version 480 (0.0008)
[2025-09-23 22:31:14,365][18541] Fps is (10 sec: 24985.8, 60 sec: 24849.1, 300 sec: 24143.5). Total num frames: 2002944. Throughput: 0: 6184.9. Samples: 489368. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:31:14,366][18541] Avg episode reward: [(0, '20.331')]
[2025-09-23 22:31:14,369][18636] Saving new best policy, reward=20.331!
[2025-09-23 22:31:14,472][18672] Updated weights for policy 0, policy_version 490 (0.0010)
[2025-09-23 22:31:16,077][18672] Updated weights for policy 0, policy_version 500 (0.0011)
[2025-09-23 22:31:17,669][18672] Updated weights for policy 0, policy_version 510 (0.0009)
[2025-09-23 22:31:19,365][18541] Fps is (10 sec: 24986.1, 60 sec: 24712.6, 300 sec: 24168.1). Total num frames: 2125824. Throughput: 0: 6216.0. Samples: 527460. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)
[2025-09-23 22:31:19,366][18541] Avg episode reward: [(0, '17.654')]
[2025-09-23 22:31:19,384][18672] Updated weights for policy 0, policy_version 520 (0.0010)
[2025-09-23 22:31:20,924][18672] Updated weights for policy 0, policy_version 530 (0.0009)
[2025-09-23 22:31:22,534][18672] Updated weights for policy 0, policy_version 540 (0.0009)
[2025-09-23 22:31:24,221][18672] Updated weights for policy 0, policy_version 550 (0.0009)
[2025-09-23 22:31:24,365][18541] Fps is (10 sec: 24985.7, 60 sec: 24849.2, 300 sec: 24234.1). Total num frames: 2252800. Throughput: 0: 6246.5. Samples: 547048. Policy #0 lag: (min: 0.0, avg: 0.8, max: 2.0)
[2025-09-23 22:31:24,366][18541] Avg episode reward: [(0, '19.841')]
[2025-09-23 22:31:25,763][18672] Updated weights for policy 0, policy_version 560 (0.0009)
[2025-09-23 22:31:27,441][18672] Updated weights for policy 0, policy_version 570 (0.0009)
[2025-09-23 22:31:29,131][18672] Updated weights for policy 0, policy_version 580 (0.0010)
[2025-09-23 22:31:29,365][18541] Fps is (10 sec: 25395.2, 60 sec: 24849.1, 300 sec: 24293.4). Total num frames: 2379776. Throughput: 0: 6220.1. Samples: 584320. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:31:29,365][18541] Avg episode reward: [(0, '20.327')]
[2025-09-23 22:31:30,788][18672] Updated weights for policy 0, policy_version 590 (0.0009)
[2025-09-23 22:31:32,588][18672] Updated weights for policy 0, policy_version 600 (0.0009)
[2025-09-23 22:31:34,275][18672] Updated weights for policy 0, policy_version 610 (0.0009)
[2025-09-23 22:31:34,365][18541] Fps is (10 sec: 24575.9, 60 sec: 24849.1, 300 sec: 24267.3). Total num frames: 2498560. Throughput: 0: 6194.8. Samples: 619938. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:31:34,366][18541] Avg episode reward: [(0, '21.605')]
[2025-09-23 22:31:34,369][18636] Saving new best policy, reward=21.605!
[2025-09-23 22:31:35,852][18672] Updated weights for policy 0, policy_version 620 (0.0010)
[2025-09-23 22:31:37,688][18672] Updated weights for policy 0, policy_version 630 (0.0010)
[2025-09-23 22:31:39,365][18541] Fps is (10 sec: 23756.8, 60 sec: 24712.6, 300 sec: 24243.7). Total num frames: 2617344. Throughput: 0: 6191.0. Samples: 638360. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:31:39,365][18541] Avg episode reward: [(0, '21.752')]
[2025-09-23 22:31:39,366][18636] Saving new best policy, reward=21.752!
[2025-09-23 22:31:39,482][18672] Updated weights for policy 0, policy_version 640 (0.0013)
[2025-09-23 22:31:41,371][18672] Updated weights for policy 0, policy_version 650 (0.0011)
[2025-09-23 22:31:43,110][18672] Updated weights for policy 0, policy_version 660 (0.0009)
[2025-09-23 22:31:44,365][18541] Fps is (10 sec: 23347.2, 60 sec: 24576.0, 300 sec: 24185.8). Total num frames: 2732032. Throughput: 0: 6126.1. Samples: 672370. Policy #0 lag: (min: 0.0, avg: 0.6, max: 2.0)
[2025-09-23 22:31:44,366][18541] Avg episode reward: [(0, '24.069')]
[2025-09-23 22:31:44,370][18636] Saving /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/checkpoint_p0/checkpoint_000000667_2732032.pth...
[2025-09-23 22:31:44,424][18636] Saving new best policy, reward=24.069!
[2025-09-23 22:31:44,733][18672] Updated weights for policy 0, policy_version 670 (0.0009)
[2025-09-23 22:31:46,412][18672] Updated weights for policy 0, policy_version 680 (0.0009)
[2025-09-23 22:31:48,144][18672] Updated weights for policy 0, policy_version 690 (0.0011)
[2025-09-23 22:31:49,365][18541] Fps is (10 sec: 23756.5, 60 sec: 24507.8, 300 sec: 24202.4). Total num frames: 2854912. Throughput: 0: 6111.5. Samples: 708918. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:31:49,366][18541] Avg episode reward: [(0, '24.722')]
[2025-09-23 22:31:49,367][18636] Saving new best policy, reward=24.722!
[2025-09-23 22:31:49,838][18672] Updated weights for policy 0, policy_version 700 (0.0011)
[2025-09-23 22:31:51,640][18672] Updated weights for policy 0, policy_version 710 (0.0010)
[2025-09-23 22:31:53,198][18672] Updated weights for policy 0, policy_version 720 (0.0008)
[2025-09-23 22:31:54,365][18541] Fps is (10 sec: 24575.5, 60 sec: 24576.0, 300 sec: 24217.5). Total num frames: 2977792. Throughput: 0: 6108.9. Samples: 726606. Policy #0 lag: (min: 0.0, avg: 0.8, max: 2.0)
[2025-09-23 22:31:54,366][18541] Avg episode reward: [(0, '23.296')]
[2025-09-23 22:31:54,776][18672] Updated weights for policy 0, policy_version 730 (0.0009)
[2025-09-23 22:31:56,332][18672] Updated weights for policy 0, policy_version 740 (0.0009)
[2025-09-23 22:31:57,918][18672] Updated weights for policy 0, policy_version 750 (0.0008)
[2025-09-23 22:31:59,365][18541] Fps is (10 sec: 24985.9, 60 sec: 24644.3, 300 sec: 24263.6). Total num frames: 3104768. Throughput: 0: 6142.3. Samples: 765770. Policy #0 lag: (min: 0.0, avg: 0.8, max: 2.0)
[2025-09-23 22:31:59,366][18541] Avg episode reward: [(0, '22.975')]
[2025-09-23 22:31:59,611][18672] Updated weights for policy 0, policy_version 760 (0.0009)
[2025-09-23 22:32:01,132][18672] Updated weights for policy 0, policy_version 770 (0.0010)
[2025-09-23 22:32:02,901][18672] Updated weights for policy 0, policy_version 780 (0.0010)
[2025-09-23 22:32:04,366][18541] Fps is (10 sec: 24985.4, 60 sec: 24575.9, 300 sec: 24275.3). Total num frames: 3227648. Throughput: 0: 6114.5. Samples: 802614. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:32:04,369][18541] Avg episode reward: [(0, '25.135')]
[2025-09-23 22:32:04,408][18636] Saving new best policy, reward=25.135!
[2025-09-23 22:32:04,595][18672] Updated weights for policy 0, policy_version 790 (0.0010)
[2025-09-23 22:32:06,246][18672] Updated weights for policy 0, policy_version 800 (0.0010)
[2025-09-23 22:32:07,929][18672] Updated weights for policy 0, policy_version 810 (0.0009)
[2025-09-23 22:32:09,365][18541] Fps is (10 sec: 24575.8, 60 sec: 24576.0, 300 sec: 24286.2). Total num frames: 3350528. Throughput: 0: 6090.1. Samples: 821102. Policy #0 lag: (min: 0.0, avg: 0.8, max: 2.0)
[2025-09-23 22:32:09,368][18541] Avg episode reward: [(0, '27.056')]
[2025-09-23 22:32:09,369][18636] Saving new best policy, reward=27.056!
[2025-09-23 22:32:09,604][18672] Updated weights for policy 0, policy_version 820 (0.0009)
[2025-09-23 22:32:11,182][18672] Updated weights for policy 0, policy_version 830 (0.0009)
[2025-09-23 22:32:12,836][18672] Updated weights for policy 0, policy_version 840 (0.0010)
[2025-09-23 22:32:14,365][18541] Fps is (10 sec: 24576.7, 60 sec: 24507.7, 300 sec: 24296.4). Total num frames: 3473408. Throughput: 0: 6088.7. Samples: 858310. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:32:14,365][18541] Avg episode reward: [(0, '27.492')]
[2025-09-23 22:32:14,378][18636] Saving new best policy, reward=27.492!
[2025-09-23 22:32:14,568][18672] Updated weights for policy 0, policy_version 850 (0.0011)
[2025-09-23 22:32:16,103][18672] Updated weights for policy 0, policy_version 860 (0.0010)
[2025-09-23 22:32:17,760][18672] Updated weights for policy 0, policy_version 870 (0.0009)
[2025-09-23 22:32:19,338][18672] Updated weights for policy 0, policy_version 880 (0.0008)
[2025-09-23 22:32:19,365][18541] Fps is (10 sec: 25395.1, 60 sec: 24644.2, 300 sec: 24361.2). Total num frames: 3604480. Throughput: 0: 6134.5. Samples: 895990. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:32:19,366][18541] Avg episode reward: [(0, '25.060')]
[2025-09-23 22:32:20,856][18672] Updated weights for policy 0, policy_version 890 (0.0009)
[2025-09-23 22:32:22,456][18672] Updated weights for policy 0, policy_version 900 (0.0009)
[2025-09-23 22:32:23,960][18672] Updated weights for policy 0, policy_version 910 (0.0008)
[2025-09-23 22:32:24,365][18541] Fps is (10 sec: 26214.3, 60 sec: 24712.5, 300 sec: 24421.8). Total num frames: 3735552. Throughput: 0: 6169.5. Samples: 915990. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:32:24,366][18541] Avg episode reward: [(0, '25.627')]
[2025-09-23 22:32:25,471][18672] Updated weights for policy 0, policy_version 920 (0.0009)
[2025-09-23 22:32:27,243][18672] Updated weights for policy 0, policy_version 930 (0.0010)
[2025-09-23 22:32:28,800][18672] Updated weights for policy 0, policy_version 940 (0.0008)
[2025-09-23 22:32:29,366][18541] Fps is (10 sec: 25804.6, 60 sec: 24712.4, 300 sec: 24452.5). Total num frames: 3862528. Throughput: 0: 6265.7. Samples: 954330. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:32:29,366][18541] Avg episode reward: [(0, '24.940')]
[2025-09-23 22:32:30,402][18672] Updated weights for policy 0, policy_version 950 (0.0009)
[2025-09-23 22:32:32,088][18672] Updated weights for policy 0, policy_version 960 (0.0009)
[2025-09-23 22:32:33,782][18672] Updated weights for policy 0, policy_version 970 (0.0009)
[2025-09-23 22:32:34,365][18541] Fps is (10 sec: 24985.3, 60 sec: 24780.7, 300 sec: 24456.3). Total num frames: 3985408. Throughput: 0: 6280.0. Samples: 991520. Policy #0 lag: (min: 0.0, avg: 0.7, max: 2.0)
[2025-09-23 22:32:34,366][18541] Avg episode reward: [(0, '24.617')]
[2025-09-23 22:32:35,029][18636] Stopping Batcher_0...
[2025-09-23 22:32:35,029][18541] Component Batcher_0 stopped!
[2025-09-23 22:32:35,029][18636] Loop batcher_evt_loop terminating...
[2025-09-23 22:32:35,030][18636] Saving /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/checkpoint_p0/checkpoint_000000978_4005888.pth...
[2025-09-23 22:32:35,063][18676] Stopping RolloutWorker_w3...
[2025-09-23 22:32:35,064][18541] Component RolloutWorker_w3 stopped!
[2025-09-23 22:32:35,064][18676] Loop rollout_proc3_evt_loop terminating...
[2025-09-23 22:32:35,071][18672] Weights refcount: 2 0
[2025-09-23 22:32:35,072][18680] Stopping RolloutWorker_w5...
[2025-09-23 22:32:35,073][18672] Stopping InferenceWorker_p0-w0...
[2025-09-23 22:32:35,073][18541] Component RolloutWorker_w5 stopped!
[2025-09-23 22:32:35,073][18680] Loop rollout_proc5_evt_loop terminating...
[2025-09-23 22:32:35,073][18672] Loop inference_proc0-0_evt_loop terminating...
[2025-09-23 22:32:35,073][18541] Component InferenceWorker_p0-w0 stopped!
[2025-09-23 22:32:35,074][18673] Stopping RolloutWorker_w0...
[2025-09-23 22:32:35,074][18541] Component RolloutWorker_w0 stopped!
[2025-09-23 22:32:35,075][18673] Loop rollout_proc0_evt_loop terminating...
[2025-09-23 22:32:35,075][18541] Component RolloutWorker_w4 stopped!
[2025-09-23 22:32:35,075][18678] Stopping RolloutWorker_w4...
[2025-09-23 22:32:35,076][18678] Loop rollout_proc4_evt_loop terminating...
[2025-09-23 22:32:35,079][18674] Stopping RolloutWorker_w1...
[2025-09-23 22:32:35,079][18541] Component RolloutWorker_w1 stopped!
[2025-09-23 22:32:35,079][18674] Loop rollout_proc1_evt_loop terminating...
[2025-09-23 22:32:35,080][18541] Component RolloutWorker_w6 stopped!
[2025-09-23 22:32:35,080][18679] Stopping RolloutWorker_w6...
[2025-09-23 22:32:35,081][18679] Loop rollout_proc6_evt_loop terminating...
[2025-09-23 22:32:35,091][18681] Stopping RolloutWorker_w7...
[2025-09-23 22:32:35,091][18541] Component RolloutWorker_w7 stopped!
[2025-09-23 22:32:35,091][18681] Loop rollout_proc7_evt_loop terminating...
[2025-09-23 22:32:35,091][18636] Saving /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/checkpoint_p0/checkpoint_000000978_4005888.pth...
[2025-09-23 22:32:35,093][18677] Stopping RolloutWorker_w2...
[2025-09-23 22:32:35,093][18541] Component RolloutWorker_w2 stopped!
[2025-09-23 22:32:35,093][18677] Loop rollout_proc2_evt_loop terminating...
[2025-09-23 22:32:35,169][18636] Stopping LearnerWorker_p0...
[2025-09-23 22:32:35,169][18541] Component LearnerWorker_p0 stopped!
[2025-09-23 22:32:35,169][18636] Loop learner_proc0_evt_loop terminating...
[2025-09-23 22:32:35,170][18541] Waiting for process learner_proc0 to stop...
[2025-09-23 22:32:36,545][18541] Waiting for process inference_proc0-0 to join...
[2025-09-23 22:32:36,546][18541] Waiting for process rollout_proc0 to join...
[2025-09-23 22:32:36,546][18541] Waiting for process rollout_proc1 to join...
[2025-09-23 22:32:36,546][18541] Waiting for process rollout_proc2 to join...
[2025-09-23 22:32:36,547][18541] Waiting for process rollout_proc3 to join...
[2025-09-23 22:32:36,547][18541] Waiting for process rollout_proc4 to join...
[2025-09-23 22:32:36,547][18541] Waiting for process rollout_proc5 to join...
[2025-09-23 22:32:36,547][18541] Waiting for process rollout_proc6 to join...
[2025-09-23 22:32:36,548][18541] Waiting for process rollout_proc7 to join...
[2025-09-23 22:32:36,548][18541] Batcher 0 profile tree view:
batching: 11.1072, releasing_batches: 0.0279
[2025-09-23 22:32:36,548][18541] InferenceWorker_p0-w0 profile tree view:
wait_policy: 0.0000
  wait_policy_total: 2.9238
update_model: 2.8049
  weight_update: 0.0009
one_step: 0.0024
  handle_policy_step: 148.5185
    deserialize: 7.1688, stack: 0.9546, obs_to_device_normalize: 38.3682, forward: 67.6133, send_messages: 8.4636
    prepare_outputs: 19.5381
      to_cpu: 12.9854
[2025-09-23 22:32:36,548][18541] Learner 0 profile tree view:
misc: 0.0054, prepare_batch: 9.4950
train: 23.5502
  epoch_init: 0.0048, minibatch_init: 0.0060, losses_postprocess: 0.1762, kl_divergence: 0.2186, after_optimizer: 7.7865
  calculate_losses: 9.4443
    losses_init: 0.0025, forward_head: 0.7255, bptt_initial: 6.4269, tail: 0.4715, advantages_returns: 0.1330, losses: 0.7146
    bptt: 0.8079
      bptt_forward_core: 0.7599
  update: 5.5586
    clip: 0.6225
[2025-09-23 22:32:36,549][18541] RolloutWorker_w0 profile tree view:
wait_for_trajectories: 0.1004, enqueue_policy_requests: 4.9267, env_step: 55.7964, overhead: 5.8992, complete_rollouts: 0.1527
save_policy_outputs: 5.1856
  split_output_tensors: 2.5891
[2025-09-23 22:32:36,549][18541] RolloutWorker_w7 profile tree view:
wait_for_trajectories: 0.1402, enqueue_policy_requests: 6.7668, env_step: 90.4812, overhead: 8.9739, complete_rollouts: 0.2167
save_policy_outputs: 8.4592
  split_output_tensors: 4.1547
[2025-09-23 22:32:36,549][18541] Loop Runner_EvtLoop terminating...
[2025-09-23 22:32:36,549][18541] Runner profile tree view:
main_loop: 169.1227
[2025-09-23 22:32:36,550][18541] Collected {0: 4005888}, FPS: 23686.3
[2025-09-23 22:32:36,564][18541] Loading existing experiment configuration from /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/config.json
[2025-09-23 22:32:36,564][18541] Overriding arg 'num_workers' with value 1 passed from command line
[2025-09-23 22:32:36,564][18541] Adding new argument 'no_render'=True that is not in the saved config file!
[2025-09-23 22:32:36,564][18541] Adding new argument 'save_video'=True that is not in the saved config file!
[2025-09-23 22:32:36,565][18541] Adding new argument 'video_frames'=1000000000.0 that is not in the saved config file!
[2025-09-23 22:32:36,565][18541] Adding new argument 'video_name'=None that is not in the saved config file!
[2025-09-23 22:32:36,565][18541] Adding new argument 'max_num_frames'=1000000000.0 that is not in the saved config file!
[2025-09-23 22:32:36,565][18541] Adding new argument 'max_num_episodes'=10 that is not in the saved config file!
[2025-09-23 22:32:36,565][18541] Adding new argument 'push_to_hub'=False that is not in the saved config file!
[2025-09-23 22:32:36,566][18541] Adding new argument 'hf_repository'=None that is not in the saved config file!
[2025-09-23 22:32:36,566][18541] Adding new argument 'policy_index'=0 that is not in the saved config file!
[2025-09-23 22:32:36,566][18541] Adding new argument 'eval_deterministic'=False that is not in the saved config file!
[2025-09-23 22:32:36,566][18541] Adding new argument 'train_script'=None that is not in the saved config file!
[2025-09-23 22:32:36,566][18541] Adding new argument 'enjoy_script'=None that is not in the saved config file!
[2025-09-23 22:32:36,566][18541] Using frameskip 1 and render_action_repeat=4 for evaluation
[2025-09-23 22:32:36,592][18541] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:32:36,592][18541] RunningMeanStd input shape: (3, 72, 128)
[2025-09-23 22:32:36,593][18541] RunningMeanStd input shape: (1,)
[2025-09-23 22:32:36,600][18541] ConvEncoder: input_channels=3
[2025-09-23 22:32:36,663][18541] Conv encoder output size: 512
[2025-09-23 22:32:36,663][18541] Policy head output size: 512
[2025-09-23 22:32:36,751][18541] Loading state from checkpoint /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/checkpoint_p0/checkpoint_000000978_4005888.pth...
[2025-09-23 22:32:36,752][18541] Could not load from checkpoint, attempt 0
Traceback (most recent call last):
  File "/home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/.venv/lib/python3.10/site-packages/sample_factory/algo/learning/learner.py", line 281, in load_checkpoint
    checkpoint_dict = torch.load(latest_checkpoint, map_location=device)
  File "/home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/.venv/lib/python3.10/site-packages/torch/serialization.py", line 1529, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy.core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy.core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
[2025-09-23 22:32:36,753][18541] Loading state from checkpoint /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/checkpoint_p0/checkpoint_000000978_4005888.pth...
[2025-09-23 22:32:36,754][18541] Could not load from checkpoint, attempt 1
Traceback (most recent call last):
  File "/home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/.venv/lib/python3.10/site-packages/sample_factory/algo/learning/learner.py", line 281, in load_checkpoint
    checkpoint_dict = torch.load(latest_checkpoint, map_location=device)
  File "/home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/.venv/lib/python3.10/site-packages/torch/serialization.py", line 1529, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy.core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy.core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
[2025-09-23 22:32:36,754][18541] Loading state from checkpoint /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/checkpoint_p0/checkpoint_000000978_4005888.pth...
[2025-09-23 22:32:36,754][18541] Could not load from checkpoint, attempt 2
Traceback (most recent call last):
  File "/home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/.venv/lib/python3.10/site-packages/sample_factory/algo/learning/learner.py", line 281, in load_checkpoint
    checkpoint_dict = torch.load(latest_checkpoint, map_location=device)
  File "/home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/.venv/lib/python3.10/site-packages/torch/serialization.py", line 1529, in load
    raise pickle.UnpicklingError(_get_wo_message(str(e))) from None
_pickle.UnpicklingError: Weights only load failed. This file can still be loaded, to do so you have two options, [1mdo those steps only if you trust the source of the checkpoint[0m. 
	(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
	(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
	WeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy.core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy.core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
[2025-09-23 22:37:04,037][24907] Saving configuration to /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/config.json...
[2025-09-23 22:37:04,045][24907] Rollout worker 0 uses device cpu
[2025-09-23 22:37:04,046][24907] Rollout worker 1 uses device cpu
[2025-09-23 22:37:04,046][24907] Rollout worker 2 uses device cpu
[2025-09-23 22:37:04,046][24907] Rollout worker 3 uses device cpu
[2025-09-23 22:37:04,046][24907] Rollout worker 4 uses device cpu
[2025-09-23 22:37:04,046][24907] Rollout worker 5 uses device cpu
[2025-09-23 22:37:04,046][24907] Rollout worker 6 uses device cpu
[2025-09-23 22:37:04,046][24907] Rollout worker 7 uses device cpu
[2025-09-23 22:37:04,125][24907] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-09-23 22:37:04,126][24907] InferenceWorker_p0-w0: min num requests: 2
[2025-09-23 22:37:04,168][24907] Starting all processes...
[2025-09-23 22:37:04,168][24907] Starting process learner_proc0
[2025-09-23 22:37:05,511][24907] Starting all processes...
[2025-09-23 22:37:05,514][24995] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-09-23 22:37:05,514][24995] Set environment var CUDA_VISIBLE_DEVICES to '0' (GPU indices [0]) for learning process 0
[2025-09-23 22:37:05,514][24907] Starting process inference_proc0-0
[2025-09-23 22:37:05,514][24907] Starting process rollout_proc0
[2025-09-23 22:37:05,515][24907] Starting process rollout_proc1
[2025-09-23 22:37:05,521][24907] Starting process rollout_proc2
[2025-09-23 22:37:05,521][24907] Starting process rollout_proc3
[2025-09-23 22:37:05,522][24907] Starting process rollout_proc4
[2025-09-23 22:37:05,523][24995] Num visible devices: 1
[2025-09-23 22:37:05,524][24995] Starting seed is not provided
[2025-09-23 22:37:05,524][24995] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-09-23 22:37:05,524][24995] Initializing actor-critic model on device cuda:0
[2025-09-23 22:37:05,524][24995] RunningMeanStd input shape: (3, 72, 128)
[2025-09-23 22:37:05,525][24995] RunningMeanStd input shape: (1,)
[2025-09-23 22:37:05,523][24907] Starting process rollout_proc5
[2025-09-23 22:37:05,533][24995] ConvEncoder: input_channels=3
[2025-09-23 22:37:05,523][24907] Starting process rollout_proc6
[2025-09-23 22:37:05,527][24907] Starting process rollout_proc7
[2025-09-23 22:37:05,602][24995] Conv encoder output size: 512
[2025-09-23 22:37:05,602][24995] Policy head output size: 512
[2025-09-23 22:37:05,611][24995] Created Actor Critic model with architecture:
[2025-09-23 22:37:05,611][24995] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer(
    (running_mean_std): RunningMeanStdDictInPlace(
      (running_mean_std): ModuleDict(
        (obs): RunningMeanStdInPlace()
      )
    )
  )
  (returns_normalizer): RecursiveScriptModule(original_name=RunningMeanStdInPlace)
  (encoder): VizdoomEncoder(
    (basic_encoder): ConvEncoder(
      (enc): RecursiveScriptModule(
        original_name=ConvEncoderImpl
        (conv_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Conv2d)
          (1): RecursiveScriptModule(original_name=ELU)
          (2): RecursiveScriptModule(original_name=Conv2d)
          (3): RecursiveScriptModule(original_name=ELU)
          (4): RecursiveScriptModule(original_name=Conv2d)
          (5): RecursiveScriptModule(original_name=ELU)
        )
        (mlp_layers): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=ELU)
        )
      )
    )
  )
  (core): ModelCoreRNN(
    (core): GRU(512, 512)
  )
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=512, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=512, out_features=5, bias=True)
  )
)
[2025-09-23 22:37:05,761][24995] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-09-23 22:37:06,772][24995] Loading state from checkpoint /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/checkpoint_p0/checkpoint_000000978_4005888.pth...
[2025-09-23 22:37:06,794][24995] Loading model from checkpoint
[2025-09-23 22:37:06,795][24995] Loaded experiment state at self.train_step=978, self.env_steps=4005888
[2025-09-23 22:37:06,796][24995] Initialized policy 0 weights for model version 978
[2025-09-23 22:37:06,798][24995] LearnerWorker_p0 finished initialization!
[2025-09-23 22:37:06,798][24995] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-09-23 22:37:07,308][25048] Worker 1 uses CPU cores [2, 3]
[2025-09-23 22:37:07,362][25044] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-09-23 22:37:07,362][25044] Set environment var CUDA_VISIBLE_DEVICES to '0' (GPU indices [0]) for inference process 0
[2025-09-23 22:37:07,372][25044] Num visible devices: 1
[2025-09-23 22:37:07,374][25052] Worker 6 uses CPU cores [12, 13]
[2025-09-23 22:37:07,438][25044] RunningMeanStd input shape: (3, 72, 128)
[2025-09-23 22:37:07,439][25045] Worker 0 uses CPU cores [0, 1]
[2025-09-23 22:37:07,439][25044] RunningMeanStd input shape: (1,)
[2025-09-23 22:37:07,448][25044] ConvEncoder: input_channels=3
[2025-09-23 22:37:07,499][25049] Worker 2 uses CPU cores [4, 5]
[2025-09-23 22:37:07,526][25044] Conv encoder output size: 512
[2025-09-23 22:37:07,526][25044] Policy head output size: 512
[2025-09-23 22:37:07,602][25051] Worker 4 uses CPU cores [8, 9]
[2025-09-23 22:37:07,906][25047] Worker 3 uses CPU cores [6, 7]
[2025-09-23 22:37:07,906][25053] Worker 7 uses CPU cores [14, 15]
[2025-09-23 22:37:07,996][24907] Inference worker 0-0 is ready!
[2025-09-23 22:37:07,996][24907] All inference workers are ready! Signal rollout workers to start!
[2025-09-23 22:37:07,996][24907] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 4005888. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-09-23 22:37:08,001][25050] Worker 5 uses CPU cores [10, 11]
[2025-09-23 22:37:08,018][25045] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:37:08,018][25047] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:37:08,019][25049] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:37:08,019][25051] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:37:08,019][25048] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:37:08,022][25050] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:37:08,035][25052] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:37:08,035][25053] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:37:08,201][25045] Decorrelating experience for 0 frames...
[2025-09-23 22:37:08,201][25047] Decorrelating experience for 0 frames...
[2025-09-23 22:37:08,201][25048] Decorrelating experience for 0 frames...
[2025-09-23 22:37:08,202][25049] Decorrelating experience for 0 frames...
[2025-09-23 22:37:08,347][25052] Decorrelating experience for 0 frames...
[2025-09-23 22:37:08,359][25048] Decorrelating experience for 32 frames...
[2025-09-23 22:37:08,359][25045] Decorrelating experience for 32 frames...
[2025-09-23 22:37:08,359][25047] Decorrelating experience for 32 frames...
[2025-09-23 22:37:08,499][25053] Decorrelating experience for 0 frames...
[2025-09-23 22:37:08,553][25050] Decorrelating experience for 0 frames...
[2025-09-23 22:37:08,553][25047] Decorrelating experience for 64 frames...
[2025-09-23 22:37:08,553][25048] Decorrelating experience for 64 frames...
[2025-09-23 22:37:08,554][25051] Decorrelating experience for 0 frames...
[2025-09-23 22:37:08,656][25045] Decorrelating experience for 64 frames...
[2025-09-23 22:37:08,712][25050] Decorrelating experience for 32 frames...
[2025-09-23 22:37:08,713][25051] Decorrelating experience for 32 frames...
[2025-09-23 22:37:08,714][25049] Decorrelating experience for 32 frames...
[2025-09-23 22:37:08,728][25048] Decorrelating experience for 96 frames...
[2025-09-23 22:37:08,728][25047] Decorrelating experience for 96 frames...
[2025-09-23 22:37:08,829][25045] Decorrelating experience for 96 frames...
[2025-09-23 22:37:08,913][25050] Decorrelating experience for 64 frames...
[2025-09-23 22:37:08,913][25051] Decorrelating experience for 64 frames...
[2025-09-23 22:37:09,013][25049] Decorrelating experience for 64 frames...
[2025-09-23 22:37:09,042][25052] Decorrelating experience for 32 frames...
[2025-09-23 22:37:09,096][25050] Decorrelating experience for 96 frames...
[2025-09-23 22:37:09,096][25051] Decorrelating experience for 96 frames...
[2025-09-23 22:37:09,197][25049] Decorrelating experience for 96 frames...
[2025-09-23 22:37:09,344][25053] Decorrelating experience for 32 frames...
[2025-09-23 22:37:09,408][25052] Decorrelating experience for 64 frames...
[2025-09-23 22:37:09,644][24995] Signal inference workers to stop experience collection...
[2025-09-23 22:37:09,647][25044] InferenceWorker_p0-w0: stopping experience collection
[2025-09-23 22:37:09,712][25053] Decorrelating experience for 64 frames...
[2025-09-23 22:37:09,732][25052] Decorrelating experience for 96 frames...
[2025-09-23 22:37:10,024][25053] Decorrelating experience for 96 frames...
[2025-09-23 22:37:10,498][24995] Signal inference workers to resume experience collection...
[2025-09-23 22:37:10,499][24995] Stopping Batcher_0...
[2025-09-23 22:37:10,499][24995] Loop batcher_evt_loop terminating...
[2025-09-23 22:37:10,507][24907] Component Batcher_0 stopped!
[2025-09-23 22:37:10,524][25044] Weights refcount: 2 0
[2025-09-23 22:37:10,526][25044] Stopping InferenceWorker_p0-w0...
[2025-09-23 22:37:10,526][25044] Loop inference_proc0-0_evt_loop terminating...
[2025-09-23 22:37:10,526][24907] Component InferenceWorker_p0-w0 stopped!
[2025-09-23 22:37:10,531][25051] Stopping RolloutWorker_w4...
[2025-09-23 22:37:10,531][25049] Stopping RolloutWorker_w2...
[2025-09-23 22:37:10,531][25050] Stopping RolloutWorker_w5...
[2025-09-23 22:37:10,531][25047] Stopping RolloutWorker_w3...
[2025-09-23 22:37:10,531][25048] Stopping RolloutWorker_w1...
[2025-09-23 22:37:10,531][24907] Component RolloutWorker_w2 stopped!
[2025-09-23 22:37:10,532][25051] Loop rollout_proc4_evt_loop terminating...
[2025-09-23 22:37:10,532][25049] Loop rollout_proc2_evt_loop terminating...
[2025-09-23 22:37:10,532][25047] Loop rollout_proc3_evt_loop terminating...
[2025-09-23 22:37:10,532][25048] Loop rollout_proc1_evt_loop terminating...
[2025-09-23 22:37:10,532][24907] Component RolloutWorker_w5 stopped!
[2025-09-23 22:37:10,532][25050] Loop rollout_proc5_evt_loop terminating...
[2025-09-23 22:37:10,532][24907] Component RolloutWorker_w3 stopped!
[2025-09-23 22:37:10,532][24907] Component RolloutWorker_w1 stopped!
[2025-09-23 22:37:10,533][24907] Component RolloutWorker_w4 stopped!
[2025-09-23 22:37:10,533][24907] Component RolloutWorker_w0 stopped!
[2025-09-23 22:37:10,533][25045] Stopping RolloutWorker_w0...
[2025-09-23 22:37:10,534][24907] Component RolloutWorker_w6 stopped!
[2025-09-23 22:37:10,534][25045] Loop rollout_proc0_evt_loop terminating...
[2025-09-23 22:37:10,534][24907] Component RolloutWorker_w7 stopped!
[2025-09-23 22:37:10,534][25052] Stopping RolloutWorker_w6...
[2025-09-23 22:37:10,534][25053] Stopping RolloutWorker_w7...
[2025-09-23 22:37:10,534][25053] Loop rollout_proc7_evt_loop terminating...
[2025-09-23 22:37:10,534][25052] Loop rollout_proc6_evt_loop terminating...
[2025-09-23 22:37:10,765][24995] Saving /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/checkpoint_p0/checkpoint_000000980_4014080.pth...
[2025-09-23 22:37:10,835][24995] Removing /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/checkpoint_p0/checkpoint_000000667_2732032.pth
[2025-09-23 22:37:10,841][24995] Saving /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/checkpoint_p0/checkpoint_000000980_4014080.pth...
[2025-09-23 22:37:10,923][24995] Stopping LearnerWorker_p0...
[2025-09-23 22:37:10,923][24995] Loop learner_proc0_evt_loop terminating...
[2025-09-23 22:37:10,923][24907] Component LearnerWorker_p0 stopped!
[2025-09-23 22:37:10,924][24907] Waiting for process learner_proc0 to stop...
[2025-09-23 22:37:11,788][24907] Waiting for process inference_proc0-0 to join...
[2025-09-23 22:37:11,789][24907] Waiting for process rollout_proc0 to join...
[2025-09-23 22:37:11,789][24907] Waiting for process rollout_proc1 to join...
[2025-09-23 22:37:11,789][24907] Waiting for process rollout_proc2 to join...
[2025-09-23 22:37:11,789][24907] Waiting for process rollout_proc3 to join...
[2025-09-23 22:37:11,790][24907] Waiting for process rollout_proc4 to join...
[2025-09-23 22:37:11,790][24907] Waiting for process rollout_proc5 to join...
[2025-09-23 22:37:11,790][24907] Waiting for process rollout_proc6 to join...
[2025-09-23 22:37:11,790][24907] Waiting for process rollout_proc7 to join...
[2025-09-23 22:37:11,790][24907] Batcher 0 profile tree view:
batching: 0.0153, releasing_batches: 0.0003
[2025-09-23 22:37:11,790][24907] InferenceWorker_p0-w0 profile tree view:
update_model: 0.0053
wait_policy: 0.0000
  wait_policy_total: 1.1943
one_step: 0.0016
  handle_policy_step: 0.8550
    deserialize: 0.0238, stack: 0.0033, obs_to_device_normalize: 0.1399, forward: 0.5802, send_messages: 0.0294
    prepare_outputs: 0.0553
      to_cpu: 0.0295
[2025-09-23 22:37:11,791][24907] Learner 0 profile tree view:
misc: 0.0000, prepare_batch: 0.5909
train: 0.6976
  epoch_init: 0.0000, minibatch_init: 0.0000, losses_postprocess: 0.0007, kl_divergence: 0.0050, after_optimizer: 0.0200
  calculate_losses: 0.2247
    losses_init: 0.0000, forward_head: 0.1792, bptt_initial: 0.0142, tail: 0.0122, advantages_returns: 0.0007, losses: 0.0126
    bptt: 0.0053
      bptt_forward_core: 0.0052
  update: 0.4464
    clip: 0.0184
[2025-09-23 22:37:11,791][24907] RolloutWorker_w0 profile tree view:
wait_for_trajectories: 0.0004, enqueue_policy_requests: 0.0170, env_step: 0.1474, overhead: 0.0162, complete_rollouts: 0.0004
save_policy_outputs: 0.0145
  split_output_tensors: 0.0072
[2025-09-23 22:37:11,791][24907] RolloutWorker_w7 profile tree view:
wait_for_trajectories: 0.0004, enqueue_policy_requests: 0.0006
[2025-09-23 22:37:11,791][24907] Loop Runner_EvtLoop terminating...
[2025-09-23 22:37:11,792][24907] Runner profile tree view:
main_loop: 7.6235
[2025-09-23 22:37:11,792][24907] Collected {0: 4014080}, FPS: 1074.6
[2025-09-23 22:37:11,803][24907] Loading existing experiment configuration from /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/config.json
[2025-09-23 22:37:11,804][24907] Overriding arg 'num_workers' with value 1 passed from command line
[2025-09-23 22:37:11,804][24907] Adding new argument 'no_render'=True that is not in the saved config file!
[2025-09-23 22:37:11,804][24907] Adding new argument 'save_video'=True that is not in the saved config file!
[2025-09-23 22:37:11,804][24907] Adding new argument 'video_frames'=1000000000.0 that is not in the saved config file!
[2025-09-23 22:37:11,805][24907] Adding new argument 'video_name'=None that is not in the saved config file!
[2025-09-23 22:37:11,805][24907] Adding new argument 'max_num_frames'=1000000000.0 that is not in the saved config file!
[2025-09-23 22:37:11,805][24907] Adding new argument 'max_num_episodes'=10 that is not in the saved config file!
[2025-09-23 22:37:11,805][24907] Adding new argument 'push_to_hub'=False that is not in the saved config file!
[2025-09-23 22:37:11,805][24907] Adding new argument 'hf_repository'=None that is not in the saved config file!
[2025-09-23 22:37:11,805][24907] Adding new argument 'policy_index'=0 that is not in the saved config file!
[2025-09-23 22:37:11,805][24907] Adding new argument 'eval_deterministic'=False that is not in the saved config file!
[2025-09-23 22:37:11,805][24907] Adding new argument 'train_script'=None that is not in the saved config file!
[2025-09-23 22:37:11,805][24907] Adding new argument 'enjoy_script'=None that is not in the saved config file!
[2025-09-23 22:37:11,805][24907] Using frameskip 1 and render_action_repeat=4 for evaluation
[2025-09-23 22:37:11,825][24907] Doom resolution: 160x120, resize resolution: (128, 72)
[2025-09-23 22:37:11,826][24907] RunningMeanStd input shape: (3, 72, 128)
[2025-09-23 22:37:11,826][24907] RunningMeanStd input shape: (1,)
[2025-09-23 22:37:11,834][24907] ConvEncoder: input_channels=3
[2025-09-23 22:37:11,897][24907] Conv encoder output size: 512
[2025-09-23 22:37:11,898][24907] Policy head output size: 512
[2025-09-23 22:37:11,991][24907] Loading state from checkpoint /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/checkpoint_p0/checkpoint_000000980_4014080.pth...
[2025-09-23 22:37:12,462][24907] Num frames 100...
[2025-09-23 22:37:12,532][24907] Num frames 200...
[2025-09-23 22:37:12,593][24907] Num frames 300...
[2025-09-23 22:37:12,652][24907] Num frames 400...
[2025-09-23 22:37:12,710][24907] Num frames 500...
[2025-09-23 22:37:12,774][24907] Num frames 600...
[2025-09-23 22:37:12,834][24907] Num frames 700...
[2025-09-23 22:37:12,893][24907] Num frames 800...
[2025-09-23 22:37:12,954][24907] Num frames 900...
[2025-09-23 22:37:13,015][24907] Num frames 1000...
[2025-09-23 22:37:13,075][24907] Num frames 1100...
[2025-09-23 22:37:13,136][24907] Num frames 1200...
[2025-09-23 22:37:13,227][24907] Avg episode rewards: #0: 30.640, true rewards: #0: 12.640
[2025-09-23 22:37:13,227][24907] Avg episode reward: 30.640, avg true_objective: 12.640
[2025-09-23 22:37:13,259][24907] Num frames 1300...
[2025-09-23 22:37:13,318][24907] Num frames 1400...
[2025-09-23 22:37:13,377][24907] Num frames 1500...
[2025-09-23 22:37:13,436][24907] Num frames 1600...
[2025-09-23 22:37:13,494][24907] Num frames 1700...
[2025-09-23 22:37:13,563][24907] Num frames 1800...
[2025-09-23 22:37:13,635][24907] Num frames 1900...
[2025-09-23 22:37:13,695][24907] Num frames 2000...
[2025-09-23 22:37:13,798][24907] Avg episode rewards: #0: 24.320, true rewards: #0: 10.320
[2025-09-23 22:37:13,799][24907] Avg episode reward: 24.320, avg true_objective: 10.320
[2025-09-23 22:37:13,833][24907] Num frames 2100...
[2025-09-23 22:37:13,901][24907] Num frames 2200...
[2025-09-23 22:37:13,960][24907] Num frames 2300...
[2025-09-23 22:37:14,019][24907] Num frames 2400...
[2025-09-23 22:37:14,091][24907] Avg episode rewards: #0: 17.440, true rewards: #0: 8.107
[2025-09-23 22:37:14,092][24907] Avg episode reward: 17.440, avg true_objective: 8.107
[2025-09-23 22:37:14,151][24907] Num frames 2500...
[2025-09-23 22:37:14,213][24907] Num frames 2600...
[2025-09-23 22:37:14,274][24907] Num frames 2700...
[2025-09-23 22:37:14,335][24907] Num frames 2800...
[2025-09-23 22:37:14,405][24907] Num frames 2900...
[2025-09-23 22:37:14,466][24907] Num frames 3000...
[2025-09-23 22:37:14,526][24907] Num frames 3100...
[2025-09-23 22:37:14,626][24907] Avg episode rewards: #0: 16.938, true rewards: #0: 7.937
[2025-09-23 22:37:14,626][24907] Avg episode reward: 16.938, avg true_objective: 7.937
[2025-09-23 22:37:14,650][24907] Num frames 3200...
[2025-09-23 22:37:14,710][24907] Num frames 3300...
[2025-09-23 22:37:14,770][24907] Num frames 3400...
[2025-09-23 22:37:14,831][24907] Num frames 3500...
[2025-09-23 22:37:14,890][24907] Num frames 3600...
[2025-09-23 22:37:14,949][24907] Num frames 3700...
[2025-09-23 22:37:15,007][24907] Num frames 3800...
[2025-09-23 22:37:15,069][24907] Num frames 3900...
[2025-09-23 22:37:15,136][24907] Num frames 4000...
[2025-09-23 22:37:15,197][24907] Num frames 4100...
[2025-09-23 22:37:15,258][24907] Num frames 4200...
[2025-09-23 22:37:15,320][24907] Num frames 4300...
[2025-09-23 22:37:15,416][24907] Avg episode rewards: #0: 18.734, true rewards: #0: 8.734
[2025-09-23 22:37:15,417][24907] Avg episode reward: 18.734, avg true_objective: 8.734
[2025-09-23 22:37:15,466][24907] Num frames 4400...
[2025-09-23 22:37:15,528][24907] Num frames 4500...
[2025-09-23 22:37:15,597][24907] Num frames 4600...
[2025-09-23 22:37:15,679][24907] Num frames 4700...
[2025-09-23 22:37:15,756][24907] Num frames 4800...
[2025-09-23 22:37:15,817][24907] Num frames 4900...
[2025-09-23 22:37:15,874][24907] Num frames 5000...
[2025-09-23 22:37:15,940][24907] Num frames 5100...
[2025-09-23 22:37:15,999][24907] Num frames 5200...
[2025-09-23 22:37:16,060][24907] Num frames 5300...
[2025-09-23 22:37:16,120][24907] Num frames 5400...
[2025-09-23 22:37:16,180][24907] Num frames 5500...
[2025-09-23 22:37:16,240][24907] Num frames 5600...
[2025-09-23 22:37:16,307][24907] Avg episode rewards: #0: 20.705, true rewards: #0: 9.372
[2025-09-23 22:37:16,307][24907] Avg episode reward: 20.705, avg true_objective: 9.372
[2025-09-23 22:37:16,362][24907] Num frames 5700...
[2025-09-23 22:37:16,422][24907] Num frames 5800...
[2025-09-23 22:37:16,488][24907] Num frames 5900...
[2025-09-23 22:37:16,550][24907] Num frames 6000...
[2025-09-23 22:37:16,609][24907] Num frames 6100...
[2025-09-23 22:37:16,669][24907] Num frames 6200...
[2025-09-23 22:37:16,730][24907] Num frames 6300...
[2025-09-23 22:37:16,801][24907] Num frames 6400...
[2025-09-23 22:37:16,860][24907] Num frames 6500...
[2025-09-23 22:37:16,919][24907] Num frames 6600...
[2025-09-23 22:37:16,978][24907] Num frames 6700...
[2025-09-23 22:37:17,038][24907] Num frames 6800...
[2025-09-23 22:37:17,097][24907] Num frames 6900...
[2025-09-23 22:37:17,155][24907] Num frames 7000...
[2025-09-23 22:37:17,216][24907] Num frames 7100...
[2025-09-23 22:37:17,277][24907] Num frames 7200...
[2025-09-23 22:37:17,338][24907] Num frames 7300...
[2025-09-23 22:37:17,397][24907] Num frames 7400...
[2025-09-23 22:37:17,456][24907] Num frames 7500...
[2025-09-23 22:37:17,554][24907] Avg episode rewards: #0: 25.679, true rewards: #0: 10.821
[2025-09-23 22:37:17,554][24907] Avg episode reward: 25.679, avg true_objective: 10.821
[2025-09-23 22:37:17,583][24907] Num frames 7600...
[2025-09-23 22:37:17,644][24907] Num frames 7700...
[2025-09-23 22:37:17,704][24907] Num frames 7800...
[2025-09-23 22:37:17,763][24907] Num frames 7900...
[2025-09-23 22:37:17,823][24907] Num frames 8000...
[2025-09-23 22:37:17,881][24907] Num frames 8100...
[2025-09-23 22:37:17,941][24907] Num frames 8200...
[2025-09-23 22:37:18,002][24907] Num frames 8300...
[2025-09-23 22:37:18,060][24907] Num frames 8400...
[2025-09-23 22:37:18,158][24907] Avg episode rewards: #0: 24.924, true rewards: #0: 10.549
[2025-09-23 22:37:18,159][24907] Avg episode reward: 24.924, avg true_objective: 10.549
[2025-09-23 22:37:18,218][24907] Num frames 8500...
[2025-09-23 22:37:18,280][24907] Num frames 8600...
[2025-09-23 22:37:18,342][24907] Num frames 8700...
[2025-09-23 22:37:18,447][24907] Avg episode rewards: #0: 22.639, true rewards: #0: 9.750
[2025-09-23 22:37:18,447][24907] Avg episode reward: 22.639, avg true_objective: 9.750
[2025-09-23 22:37:18,475][24907] Num frames 8800...
[2025-09-23 22:37:18,538][24907] Num frames 8900...
[2025-09-23 22:37:18,610][24907] Num frames 9000...
[2025-09-23 22:37:18,669][24907] Num frames 9100...
[2025-09-23 22:37:18,728][24907] Num frames 9200...
[2025-09-23 22:37:18,788][24907] Num frames 9300...
[2025-09-23 22:37:18,863][24907] Num frames 9400...
[2025-09-23 22:37:18,921][24907] Num frames 9500...
[2025-09-23 22:37:18,979][24907] Avg episode rewards: #0: 21.611, true rewards: #0: 9.511
[2025-09-23 22:37:18,980][24907] Avg episode reward: 21.611, avg true_objective: 9.511
[2025-09-23 22:37:31,635][24907] Replay video saved to /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/replay.mp4!
[2025-09-23 22:37:31,652][24907] Loading existing experiment configuration from /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/config.json
[2025-09-23 22:37:31,652][24907] Overriding arg 'num_workers' with value 1 passed from command line
[2025-09-23 22:37:31,652][24907] Adding new argument 'no_render'=True that is not in the saved config file!
[2025-09-23 22:37:31,652][24907] Adding new argument 'save_video'=True that is not in the saved config file!
[2025-09-23 22:37:31,652][24907] Adding new argument 'video_frames'=1000000000.0 that is not in the saved config file!
[2025-09-23 22:37:31,652][24907] Adding new argument 'video_name'=None that is not in the saved config file!
[2025-09-23 22:37:31,652][24907] Adding new argument 'max_num_frames'=100000 that is not in the saved config file!
[2025-09-23 22:37:31,652][24907] Adding new argument 'max_num_episodes'=10 that is not in the saved config file!
[2025-09-23 22:37:31,652][24907] Adding new argument 'push_to_hub'=True that is not in the saved config file!
[2025-09-23 22:37:31,652][24907] Adding new argument 'hf_repository'='OxoGhost/rl_course_vizdoom_health_gathering_supreme' that is not in the saved config file!
[2025-09-23 22:37:31,652][24907] Adding new argument 'policy_index'=0 that is not in the saved config file!
[2025-09-23 22:37:31,652][24907] Adding new argument 'eval_deterministic'=False that is not in the saved config file!
[2025-09-23 22:37:31,653][24907] Adding new argument 'train_script'=None that is not in the saved config file!
[2025-09-23 22:37:31,653][24907] Adding new argument 'enjoy_script'=None that is not in the saved config file!
[2025-09-23 22:37:31,653][24907] Using frameskip 1 and render_action_repeat=4 for evaluation
[2025-09-23 22:37:31,664][24907] RunningMeanStd input shape: (3, 72, 128)
[2025-09-23 22:37:31,664][24907] RunningMeanStd input shape: (1,)
[2025-09-23 22:37:31,671][24907] ConvEncoder: input_channels=3
[2025-09-23 22:37:31,700][24907] Conv encoder output size: 512
[2025-09-23 22:37:31,700][24907] Policy head output size: 512
[2025-09-23 22:37:31,715][24907] Loading state from checkpoint /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/checkpoint_p0/checkpoint_000000980_4014080.pth...
[2025-09-23 22:37:31,994][24907] Num frames 100...
[2025-09-23 22:37:32,057][24907] Num frames 200...
[2025-09-23 22:37:32,114][24907] Num frames 300...
[2025-09-23 22:37:32,186][24907] Num frames 400...
[2025-09-23 22:37:32,257][24907] Num frames 500...
[2025-09-23 22:37:32,318][24907] Num frames 600...
[2025-09-23 22:37:32,377][24907] Num frames 700...
[2025-09-23 22:37:32,436][24907] Num frames 800...
[2025-09-23 22:37:32,496][24907] Num frames 900...
[2025-09-23 22:37:32,554][24907] Num frames 1000...
[2025-09-23 22:37:32,617][24907] Num frames 1100...
[2025-09-23 22:37:32,675][24907] Num frames 1200...
[2025-09-23 22:37:32,736][24907] Num frames 1300...
[2025-09-23 22:37:32,796][24907] Num frames 1400...
[2025-09-23 22:37:32,855][24907] Num frames 1500...
[2025-09-23 22:37:32,916][24907] Num frames 1600...
[2025-09-23 22:37:32,977][24907] Num frames 1700...
[2025-09-23 22:37:33,037][24907] Num frames 1800...
[2025-09-23 22:37:33,098][24907] Num frames 1900...
[2025-09-23 22:37:33,158][24907] Num frames 2000...
[2025-09-23 22:37:33,218][24907] Num frames 2100...
[2025-09-23 22:37:33,269][24907] Avg episode rewards: #0: 62.999, true rewards: #0: 21.000
[2025-09-23 22:37:33,269][24907] Avg episode reward: 62.999, avg true_objective: 21.000
[2025-09-23 22:37:33,339][24907] Num frames 2200...
[2025-09-23 22:37:33,414][24907] Num frames 2300...
[2025-09-23 22:37:33,473][24907] Num frames 2400...
[2025-09-23 22:37:33,533][24907] Num frames 2500...
[2025-09-23 22:37:33,597][24907] Num frames 2600...
[2025-09-23 22:37:33,657][24907] Num frames 2700...
[2025-09-23 22:37:33,737][24907] Num frames 2800...
[2025-09-23 22:37:33,795][24907] Num frames 2900...
[2025-09-23 22:37:33,853][24907] Num frames 3000...
[2025-09-23 22:37:33,911][24907] Num frames 3100...
[2025-09-23 22:37:33,971][24907] Num frames 3200...
[2025-09-23 22:37:34,035][24907] Avg episode rewards: #0: 43.099, true rewards: #0: 16.100
[2025-09-23 22:37:34,036][24907] Avg episode reward: 43.099, avg true_objective: 16.100
[2025-09-23 22:37:34,114][24907] Num frames 3300...
[2025-09-23 22:37:34,171][24907] Num frames 3400...
[2025-09-23 22:37:34,253][24907] Num frames 3500...
[2025-09-23 22:37:34,310][24907] Num frames 3600...
[2025-09-23 22:37:34,370][24907] Num frames 3700...
[2025-09-23 22:37:34,434][24907] Num frames 3800...
[2025-09-23 22:37:34,493][24907] Num frames 3900...
[2025-09-23 22:37:34,560][24907] Num frames 4000...
[2025-09-23 22:37:34,619][24907] Num frames 4100...
[2025-09-23 22:37:34,675][24907] Num frames 4200...
[2025-09-23 22:37:34,732][24907] Num frames 4300...
[2025-09-23 22:37:34,816][24907] Num frames 4400...
[2025-09-23 22:37:34,873][24907] Num frames 4500...
[2025-09-23 22:37:34,986][24907] Avg episode rewards: #0: 39.653, true rewards: #0: 15.320
[2025-09-23 22:37:34,987][24907] Avg episode reward: 39.653, avg true_objective: 15.320
[2025-09-23 22:37:34,993][24907] Num frames 4600...
[2025-09-23 22:37:35,063][24907] Num frames 4700...
[2025-09-23 22:37:35,123][24907] Num frames 4800...
[2025-09-23 22:37:35,180][24907] Num frames 4900...
[2025-09-23 22:37:35,236][24907] Num frames 5000...
[2025-09-23 22:37:35,298][24907] Num frames 5100...
[2025-09-23 22:37:35,357][24907] Num frames 5200...
[2025-09-23 22:37:35,440][24907] Num frames 5300...
[2025-09-23 22:37:35,512][24907] Num frames 5400...
[2025-09-23 22:37:35,613][24907] Avg episode rewards: #0: 34.430, true rewards: #0: 13.680
[2025-09-23 22:37:35,614][24907] Avg episode reward: 34.430, avg true_objective: 13.680
[2025-09-23 22:37:35,644][24907] Num frames 5500...
[2025-09-23 22:37:35,707][24907] Num frames 5600...
[2025-09-23 22:37:35,769][24907] Num frames 5700...
[2025-09-23 22:37:35,832][24907] Num frames 5800...
[2025-09-23 22:37:35,889][24907] Num frames 5900...
[2025-09-23 22:37:35,949][24907] Num frames 6000...
[2025-09-23 22:37:36,016][24907] Num frames 6100...
[2025-09-23 22:37:36,098][24907] Avg episode rewards: #0: 30.488, true rewards: #0: 12.288
[2025-09-23 22:37:36,099][24907] Avg episode reward: 30.488, avg true_objective: 12.288
[2025-09-23 22:37:36,146][24907] Num frames 6200...
[2025-09-23 22:37:36,229][24907] Num frames 6300...
[2025-09-23 22:37:36,294][24907] Num frames 6400...
[2025-09-23 22:37:36,367][24907] Avg episode rewards: #0: 26.047, true rewards: #0: 10.713
[2025-09-23 22:37:36,368][24907] Avg episode reward: 26.047, avg true_objective: 10.713
[2025-09-23 22:37:36,423][24907] Num frames 6500...
[2025-09-23 22:37:36,498][24907] Num frames 6600...
[2025-09-23 22:37:36,561][24907] Num frames 6700...
[2025-09-23 22:37:36,635][24907] Num frames 6800...
[2025-09-23 22:37:36,695][24907] Num frames 6900...
[2025-09-23 22:37:36,755][24907] Num frames 7000...
[2025-09-23 22:37:36,815][24907] Num frames 7100...
[2025-09-23 22:37:36,873][24907] Num frames 7200...
[2025-09-23 22:37:36,932][24907] Num frames 7300...
[2025-09-23 22:37:36,990][24907] Num frames 7400...
[2025-09-23 22:37:37,048][24907] Num frames 7500...
[2025-09-23 22:37:37,107][24907] Num frames 7600...
[2025-09-23 22:37:37,165][24907] Num frames 7700...
[2025-09-23 22:37:37,220][24907] Num frames 7800...
[2025-09-23 22:37:37,315][24907] Avg episode rewards: #0: 27.526, true rewards: #0: 11.240
[2025-09-23 22:37:37,316][24907] Avg episode reward: 27.526, avg true_objective: 11.240
[2025-09-23 22:37:37,348][24907] Num frames 7900...
[2025-09-23 22:37:37,406][24907] Num frames 8000...
[2025-09-23 22:37:37,461][24907] Num frames 8100...
[2025-09-23 22:37:37,523][24907] Num frames 8200...
[2025-09-23 22:37:37,585][24907] Num frames 8300...
[2025-09-23 22:37:37,644][24907] Num frames 8400...
[2025-09-23 22:37:37,710][24907] Num frames 8500...
[2025-09-23 22:37:37,765][24907] Num frames 8600...
[2025-09-23 22:37:37,821][24907] Num frames 8700...
[2025-09-23 22:37:37,883][24907] Num frames 8800...
[2025-09-23 22:37:37,942][24907] Num frames 8900...
[2025-09-23 22:37:38,002][24907] Num frames 9000...
[2025-09-23 22:37:38,067][24907] Avg episode rewards: #0: 27.650, true rewards: #0: 11.275
[2025-09-23 22:37:38,068][24907] Avg episode reward: 27.650, avg true_objective: 11.275
[2025-09-23 22:37:38,125][24907] Num frames 9100...
[2025-09-23 22:37:38,184][24907] Num frames 9200...
[2025-09-23 22:37:38,241][24907] Num frames 9300...
[2025-09-23 22:37:38,299][24907] Num frames 9400...
[2025-09-23 22:37:38,358][24907] Num frames 9500...
[2025-09-23 22:37:38,417][24907] Num frames 9600...
[2025-09-23 22:37:38,476][24907] Num frames 9700...
[2025-09-23 22:37:38,538][24907] Num frames 9800...
[2025-09-23 22:37:38,598][24907] Num frames 9900...
[2025-09-23 22:37:38,657][24907] Num frames 10000...
[2025-09-23 22:37:38,720][24907] Num frames 10100...
[2025-09-23 22:37:38,782][24907] Num frames 10200...
[2025-09-23 22:37:38,841][24907] Num frames 10300...
[2025-09-23 22:37:38,901][24907] Num frames 10400...
[2025-09-23 22:37:38,962][24907] Num frames 10500...
[2025-09-23 22:37:39,024][24907] Num frames 10600...
[2025-09-23 22:37:39,084][24907] Num frames 10700...
[2025-09-23 22:37:39,146][24907] Num frames 10800...
[2025-09-23 22:37:39,226][24907] Avg episode rewards: #0: 29.938, true rewards: #0: 12.049
[2025-09-23 22:37:39,227][24907] Avg episode reward: 29.938, avg true_objective: 12.049
[2025-09-23 22:37:39,301][24907] Num frames 10900...
[2025-09-23 22:37:39,370][24907] Num frames 11000...
[2025-09-23 22:37:39,428][24907] Num frames 11100...
[2025-09-23 22:37:39,489][24907] Num frames 11200...
[2025-09-23 22:37:39,547][24907] Num frames 11300...
[2025-09-23 22:37:39,619][24907] Num frames 11400...
[2025-09-23 22:37:39,680][24907] Num frames 11500...
[2025-09-23 22:37:39,792][24907] Avg episode rewards: #0: 28.599, true rewards: #0: 11.599
[2025-09-23 22:37:39,792][24907] Avg episode reward: 28.599, avg true_objective: 11.599
[2025-09-23 22:37:39,794][24907] Num frames 11600...
[2025-09-23 22:37:55,414][24907] Replay video saved to /home/oxoghost/Documents/SynologyDrive/Python/DeepReinforcmentLearning/train_dir/default_experiment/replay.mp4!
[2025-09-23 22:38:01,823][24907] The model has been pushed to https://huggingface.co/OxoGhost/rl_course_vizdoom_health_gathering_supreme
